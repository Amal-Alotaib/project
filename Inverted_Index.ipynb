{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a38499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install required libraries\n",
    "!pip install Arabic-Stopwords\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from snowballstemmer import stemmer\n",
    "from tqdm import tqdm\n",
    "import arabicstopwords.arabicstopwords as stp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd3dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Arabic stop words\n",
    "stopWords = set(stp.stopwords_list())\n",
    "\n",
    "# Function to remove stop words\n",
    "def remove_stop_words(sentence):\n",
    "    terms = []\n",
    "    for term in sentence.split():\n",
    "        if term not in stopWords:\n",
    "            terms.append(term)\n",
    "    return \" \".join(terms)\n",
    "\n",
    "# Function to normalize Arabic text\n",
    "def normalize(text):\n",
    "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    return text\n",
    "\n",
    "# Arabic stemmer\n",
    "ar_stemmer = stemmer(\"arabic\")\n",
    "\n",
    "# Function to stem words\n",
    "def stem(sentence):\n",
    "    return \" \".join([ar_stemmer.stemWord(i) for i in sentence.split()])\n",
    "\n",
    "# Full preprocessing pipeline\n",
    "def preprocess(sentence):\n",
    "    sentence = remove_stop_words(sentence)\n",
    "    sentence = normalize(sentence)\n",
    "    sentence = stem(sentence)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e681966",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to build an inverted index\n",
    "def build_inverted_index(documents):\n",
    "    inverted_index = {}\n",
    "    for doc_id, text in enumerate(documents):\n",
    "        # Preprocess the document\n",
    "        processed_text = preprocess(text)\n",
    "        terms = processed_text.split()\n",
    "\n",
    "        # Populate the inverted index\n",
    "        for term in terms:\n",
    "            if term in inverted_index:\n",
    "                inverted_index[term].add(doc_id)\n",
    "            else:\n",
    "                inverted_index[term] = {doc_id}\n",
    "    return inverted_index\n",
    "\n",
    "# Example documents\n",
    "documents = [\n",
    "    \"هذا هو النص الأول للتجربة\",\n",
    "    \"النص الثاني يحتوي على كلمات مختلفة\",\n",
    "    \"النص الثالث يحتوي على كلمات متشابهة مع النص الأول\"\n",
    "]\n",
    "\n",
    "# Build the inverted index\n",
    "inverted_index = build_inverted_index(documents)\n",
    "\n",
    "# Display the inverted index\n",
    "for term, doc_ids in inverted_index.items():\n",
    "    print(f\"{term}: {sorted(doc_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdef60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to query the inverted index\n",
    "def query_inverted_index(term, inverted_index):\n",
    "    term = preprocess(term)  # preprocess the query term\n",
    "    return inverted_index.get(term, set())\n",
    "\n",
    "# Example query\n",
    "query_term = \"التجربة\"\n",
    "result = query_inverted_index(query_term, inverted_index)\n",
    "\n",
    "print(f\"Documents containing '{query_term}': {sorted(result)}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
